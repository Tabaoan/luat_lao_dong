# File: excel_visualize/rag_core.py
import os
import pandas as pd
from typing import Dict, Any, List
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# Load environment variables
load_dotenv()
EXCEL_PATH = os.getenv("EXCEL_FILE_PATH")

OPENAI_API_KEY = os.getenv("OPENAI__API_KEY") 

class ExcelQueryAgent:
    def __init__(self):
        self.excel_path = EXCEL_PATH
        self.df = self._load_data()
        
        # --- GIA C·ªê PH·∫¶N KH·ªûI T·∫†O C·ªòT ---
        # ƒê·∫£m b·∫£o c√°c c·ªôt chu·∫©n h√≥a lu√¥n t·ªìn t·∫°i ƒë·ªÉ tr√°nh KeyError sau n√†y
        if not self.df.empty:
            # 1. Chu·∫©n h√≥a c·ªôt Lo·∫°i (N·∫øu kh√¥ng c√≥ th√¨ t·∫°o m·∫∑c ƒë·ªãnh l√† r·ªóng)
            if "Lo·∫°i" in self.df.columns:
                self.df["Lo·∫°i_norm"] = self.df["Lo·∫°i"].astype(str).str.lower().str.strip()
            else:
                print(" C·∫£nh b√°o: File Excel thi·∫øu c·ªôt 'Lo·∫°i'. M·∫∑c ƒë·ªãnh coi t·∫•t c·∫£ l√† Khu c√¥ng nghi·ªáp.")
                self.df["Lo·∫°i_norm"] = "khu c√¥ng nghi·ªáp" # Gi√° tr·ªã fallback

            # 2. Chu·∫©n h√≥a c·ªôt T√™n (N·∫øu kh√¥ng c√≥ c·ªôt T√™n th√¨ l·ªói lu√¥n v√¨ ƒë√¢y l√† c·ªôt b·∫Øt bu·ªôc)
            if "T√™n" in self.df.columns:
                self.df["T√™n_norm"] = self.df["T√™n"].astype(str).str.lower().str.strip()
            else:
                self.df["T√™n_norm"] = ""
            
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo", 
            temperature=0, 
            api_key=OPENAI_API_KEY
        )
        
        # Safely get provinces list
        if not self.df.empty and "T·ªânh/Th√†nh ph·ªë" in self.df.columns:
            self.provinces_list = self.df["T·ªânh/Th√†nh ph·ªë"].dropna().unique().tolist()
        else:
            self.provinces_list = []

    def _load_data(self) -> pd.DataFrame:
        """ƒê·ªçc d·ªØ li·ªáu an to√†n"""
        if not self.excel_path or not os.path.exists(self.excel_path):
            # Fallback logic
            if self.excel_path:
                alt_path = self.excel_path.replace(".xlsx", ".csv")
                if os.path.exists(alt_path): return pd.read_csv(alt_path)
            
            backup = "data/IIPMap_FULL_63_COMPLETE.xlsx - Sheet1.csv"
            if os.path.exists(backup): return pd.read_csv(backup)
            
            print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu t·∫°i {self.excel_path}")
            return pd.DataFrame() # Tr·∫£ v·ªÅ DF r·ªóng thay v√¨ crash

        try: 
            return pd.read_excel(self.excel_path, sheet_name=0)
        except: 
            return pd.read_csv(self.excel_path.replace(".xlsx", ".csv"))

    def retrieve_filters(self, user_query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch c√¢u h·ªèi ƒë·ªÉ l·∫•y filters
        """
        if self.df.empty:
             return {"filter_type": "error", "message": "Ch∆∞a load ƒë∆∞·ª£c d·ªØ li·ªáu Excel."}

        parser = JsonOutputParser()
        provinces_str = ", ".join([str(p) for p in self.provinces_list])
        
        prompt_template = """
        B·∫°n l√† tr·ª£ l√Ω d·ªØ li·ªáu.
        
        DANH S√ÅCH T·ªàNH: [{provinces_list}]
        
        C√ÇU H·ªéI: "{query}"
        
        NHI·ªÜM V·ª§:
        Ph√¢n t√≠ch c√¢u h·ªèi v√† tr·∫£ v·ªÅ JSON ƒë·ªÉ l·ªçc d·ªØ li·ªáu Excel.
        
        Quy t·∫Øc x√°c ƒë·ªãnh "target_type" (Lo·∫°i h√¨nh):
        - N·∫øu user nh·∫Øc ƒë·∫øn "C·ª•m", "CCN", "C·ª•m c√¥ng nghi·ªáp" -> "C·ª•m c√¥ng nghi·ªáp"
        - N·∫øu user nh·∫Øc ƒë·∫øn "Khu", "KCN", "Khu c√¥ng nghi·ªáp" ho·∫∑c KH√îNG n√≥i g√¨ c·ª• th·ªÉ -> "Khu c√¥ng nghi·ªáp" (M·∫∑c ƒë·ªãnh).
        
        Quy t·∫Øc x√°c ƒë·ªãnh "filter_type" (Ph·∫°m vi):
        1. Type "province": User h·ªèi v·ªÅ T·ªânh (VD: "Gi√° ƒë·∫•t t·∫°i H√† Nam", "C√°c c·ª•m ·ªü B·∫Øc Ninh").
           -> "keywords": ["T√™n t·ªânh chu·∫©n x√°c"].
        2. Type "specific_zones": User nh·∫Øc t√™n ri√™ng (VD: "KCN Vsip", "So s√°nh ƒê·ªìng VƒÉn v√† H√≤a M·∫°c").
           -> "keywords": ["T√™n ri√™ng 1", "T√™n ri√™ng 2"]. (L∆∞u √Ω: Ch·ªâ l·∫•y t√™n ri√™ng, b·ªè ch·ªØ 'Khu c√¥ng nghi·ªáp', b·ªè t√™n t·ªânh ph√≠a sau. VD: "KCN Vsip B·∫Øc Ninh" -> ch·ªâ l·∫•y "Vsip").
           
        OUTPUT JSON:
        {{
            "target_type": "Khu c√¥ng nghi·ªáp" ho·∫∑c "C·ª•m c√¥ng nghi·ªáp",
            "filter_type": "province" ho·∫∑c "specific_zones",
            "search_keywords": ["Keyword1", "Keyword2"]
        }}
        """

        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["query", "provinces_list"],
        )

        try:
            print(f"üîç Analyzing query: {user_query}")
            chain = prompt | self.llm | parser
            llm_result = chain.invoke({"query": user_query, "provinces_list": provinces_str})
            
            target_type = llm_result.get("target_type", "Khu c√¥ng nghi·ªáp")
            filter_type = llm_result.get("filter_type", "error")
            keywords = llm_result.get("search_keywords", [])
            
            # --- LOGIC L·ªåC PYTHON ---
            
            # 1. L·ªçc theo Lo·∫°i h√¨nh
            # S·ª≠ d·ª•ng c·ªôt Lo·∫°i_norm ƒë√£ ƒë∆∞·ª£c ƒë·∫£m b·∫£o t·ªìn t·∫°i ·ªü __init__
            if "c·ª•m" in target_type.lower():
                type_mask = self.df["Lo·∫°i_norm"].str.contains("c·ª•m|ccn", na=False)
            else:
                type_mask = self.df["Lo·∫°i_norm"].str.contains("khu|kcn", na=False)
            
            df_by_type = self.df[type_mask].copy()

            final_result = {
                "industrial_type": target_type,
                "filter_type": filter_type,
                "data": pd.DataFrame()
            }

            # 2. L·ªçc chi ti·∫øt
            if filter_type == "province":
                # L·ªçc theo danh s√°ch t·ªânh
                mask = df_by_type["T·ªânh/Th√†nh ph·ªë"].astype(str).isin(keywords)
                final_result["data"] = df_by_type[mask]
                
            elif filter_type == "specific_zones":
                # L·ªçc theo t√™n ch·ª©a t·ª´ kh√≥a
                masks = []
                for kw in keywords:
                    # GIA C·ªê: Th√™m regex=False ƒë·ªÉ tr√°nh l·ªói n·∫øu t√™n c√≥ d·∫•u ngo·∫∑c ()
                    m = df_by_type["T√™n_norm"].str.contains(kw.lower(), regex=False, na=False)
                    masks.append(m)
                
                if masks:
                    final_mask = pd.concat(masks, axis=1).any(axis=1)
                    final_result["data"] = df_by_type[final_mask]
            
            return final_result

        except Exception as e:
            print(f"‚ùå Query Error: {e}")
            return {"filter_type": "error", "message": str(e)}

# Export
rag_agent = ExcelQueryAgent()