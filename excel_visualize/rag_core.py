# File: excel_visualize/rag_core.py
import os
import pandas as pd
import re
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# Load environment variables
load_dotenv()
EXCEL_PATH = os.getenv("EXCEL_FILE_PATH")
OPENAI_API_KEY = os.getenv("OPENAI__API_KEY") 

class ExcelQueryAgent:
    def __init__(self):
        self.excel_path = EXCEL_PATH
        self.df = self._load_data()
        
        # --- GIA C·ªê & CHU·∫®N H√ìA D·ªÆ LI·ªÜU ---
        if not self.df.empty:
            # 1. Chu·∫©n h√≥a c·ªôt Lo·∫°i
            if "Lo·∫°i" in self.df.columns:
                self.df["Lo·∫°i_norm"] = self.df["Lo·∫°i"].astype(str).str.lower().str.strip()
            else:
                self.df["Lo·∫°i_norm"] = "khu c√¥ng nghi·ªáp"

            # 2. Chu·∫©n h√≥a c·ªôt T√™n
            if "T√™n" in self.df.columns:
                self.df["T√™n_norm"] = self.df["T√™n"].astype(str).str.lower().str.strip()
            else:
                self.df["T√™n_norm"] = ""

            # 3. T√≠nh to√°n c·ªôt s·ªë li·ªáu (Gi√° & Di·ªán t√≠ch)
            if "Gi√° thu√™ ƒë·∫•t" in self.df.columns:
                self.df["Price_num"] = self.df["Gi√° thu√™ ƒë·∫•t"].apply(self._parse_price)
            else:
                self.df["Price_num"] = None

            if "T·ªïng di·ªán t√≠ch" in self.df.columns:
                self.df["Area_num"] = self.df["T·ªïng di·ªán t√≠ch"].apply(self._parse_area)
            else:
                self.df["Area_num"] = None
            
        try:
            self.llm = ChatOpenAI(
                model="gpt-3.5-turbo", 
                temperature=0, 
                api_key=OPENAI_API_KEY
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Cannot initialize LLM for excel_visualize: {e}")
            self.llm = None
        
        if not self.df.empty and "T·ªânh/Th√†nh ph·ªë" in self.df.columns:
            self.provinces_list = self.df["T·ªânh/Th√†nh ph·ªë"].dropna().unique().tolist()
        else:
            self.provinces_list = []

    def _load_data(self) -> pd.DataFrame:
        if not self.excel_path or not os.path.exists(self.excel_path):
            if self.excel_path:
                alt_path = self.excel_path.replace(".xlsx", ".csv")
                if os.path.exists(alt_path): return pd.read_csv(alt_path)
            backup = "data/IIPMap_FULL_63_COMPLETE.xlsx - Sheet1.csv"
            if os.path.exists(backup): return pd.read_csv(backup)
            print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu t·∫°i {self.excel_path}")
            return pd.DataFrame()

        try: return pd.read_excel(self.excel_path, sheet_name=0)
        except: return pd.read_csv(self.excel_path.replace(".xlsx", ".csv"))

    def _parse_price(self, value) -> Optional[float]:
        if pd.isna(value): return None
        s = str(value).lower().strip()
        for kw in ["usd/m¬≤/nƒÉm", "usd/m2/nƒÉm", "usd", "/m2", "/nƒÉm", "m2"]:
            s = s.replace(kw, "")
        s = s.strip()
        if "-" in s:
            try:
                parts = s.split("-")
                return (float(parts[0]) + float(parts[1])) / 2
            except: return None
        try: return float(s)
        except: return None

    def _parse_area(self, value) -> Optional[float]:
        if pd.isna(value): return None
        s = str(value).lower().strip()
        s = s.replace("ha", "").replace("hecta", "").replace(",", ".").strip()
        try: return float(s)
        except: return None

    def retrieve_filters(self, user_query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch c√¢u h·ªèi: X√°c ƒë·ªãnh Lo·∫°i bi·ªÉu ƒë·ªì (Gi√°/Di·ªán t√≠ch/Dual) V√Ä D·∫°ng bi·ªÉu ƒë·ªì (Tr√≤n/ƒê∆∞·ªùng/C·ªôt).
        """
        if self.df.empty:
             return {"filter_type": "error", "message": "Ch∆∞a load ƒë∆∞·ª£c d·ªØ li·ªáu Excel."}

        # Fallback khi kh√¥ng c√≥ LLM
        if not self.llm:
            return self._retrieve_filters_fallback(user_query)

        parser = JsonOutputParser()
        provinces_str = ", ".join([str(p) for p in self.provinces_list])
        
        prompt_template = """
        B·∫°n l√† chuy√™n gia d·ªØ li·ªáu B·∫•t ƒë·ªông s·∫£n c√¥ng nghi·ªáp.
        
        DANH S√ÅCH T·ªàNH: [{provinces_list}]
        C√ÇU H·ªéI: "{query}"
        
        NHI·ªÜM V·ª§: Tr√≠ch xu·∫•t JSON ƒëi·ªÅu ki·ªán l·ªçc, D·ªÆ LI·ªÜU C·∫¶N V·∫º v√† D·∫†NG BI·ªÇU ƒê·ªí.
        
        1. "target_type": Ch·ªçn M·ªòT trong ba gi√° tr·ªã sau:
           - "Khu c√¥ng nghi·ªáp": N·∫øu ch·ªâ h·ªèi v·ªÅ KCN
           - "C·ª•m c√¥ng nghi·ªáp": N·∫øu ch·ªâ h·ªèi v·ªÅ CCN  
           - "C·∫£ hai": N·∫øu h·ªèi v·ªÅ c·∫£ KCN v√† CCN (v√≠ d·ª•: "khu v√† c·ª•m c√¥ng nghi·ªáp")
        
        2. "filter_type": 
           - "province": N·∫øu user h·ªèi v·ªÅ T·ªânh.
           - "specific_zones": N·∫øu h·ªèi v·ªÅ T√™n KCN ho·∫∑c l·ªçc theo s·ªë li·ªáu.
        
        3. "search_keywords":
           - T√™n T·ªânh (n·∫øu filter_type=province).
           - T√™n KCN c·ª• th·ªÉ ho·∫∑c Th∆∞∆°ng hi·ªáu (VSIP, Amata...).
             + N·∫øu c√≥ s·ªë hi·ªáu (VSIP I): Gi·ªØ nguy√™n "VSIP I".
             + N·∫øu t√™n th∆∞∆°ng hi·ªáu chung (VSIP): Gi·ªØ nguy√™n "VSIP".
        
        4. "visualization_metric" (D·ªÆ LI·ªÜU C·∫¶N V·∫º):
           - "price": N·∫øu user h·ªèi c·ª• th·ªÉ v·ªÅ GI√Å, TI·ªÄN, USD, THU√ä.
           - "area": N·∫øu user h·ªèi c·ª• th·ªÉ v·ªÅ DI·ªÜN T√çCH, R·ªòNG, QUY M√î, HA.
           - "dual": N·∫øu user h·ªèi CHUNG CHUNG (VD: "v·∫Ω bi·ªÉu ƒë·ªì KCN A", "th√¥ng tin KCN B", "so s√°nh KCN A v√† B") m√† KH√îNG nh·∫Øc r√µ gi√° hay di·ªán t√≠ch. Ho·∫∑c nh·∫Øc ƒë·∫øn C·∫¢ HAI.
        
        5. "chart_type" (D·∫†NG BI·ªÇU ƒê·ªí - M·ªöI):
           - "bar": M·∫∑c ƒë·ªãnh (n·∫øu kh√¥ng n√≥i g√¨), ho·∫∑c user n√≥i "bi·ªÉu ƒë·ªì c·ªôt".
           - "barh": N·∫øu user n√≥i "c·ªôt ngang", "thanh ngang".
           - "pie": N·∫øu user n√≥i "bi·ªÉu ƒë·ªì tr√≤n", "c∆° c·∫•u", "t·ª∑ l·ªá", "b√°nh".
           - "line": N·∫øu user n√≥i "bi·ªÉu ƒë·ªì ƒë∆∞·ªùng", "xu h∆∞·ªõng", "bi·∫øn thi√™n".
        
        6. "numeric_filters":
           - "metric": "price" ho·∫∑c "area".
           - "operator": ">", "<", "=", ">=", "<=".
           - "value": S·ªë th·ª±c.
        
        QUAN TR·ªåNG: CH·ªà TR·∫¢ V·ªÄ JSON H·ª¢P L·ªÜ, KH√îNG C√ì MARKDOWN, KH√îNG C√ì TEXT TH√äM.
        
        OUTPUT JSON:
        {{
            "target_type": "Khu c√¥ng nghi·ªáp",
            "filter_type": "province",
            "search_keywords": ["H·∫£i Ph√≤ng"],
            "visualization_metric": "dual",
            "chart_type": "bar",
            "numeric_filters": []
        }}
        """

        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["query", "provinces_list"],
        )

        try:
            print(f"üîç Analyzing query: {user_query}")
            chain = prompt | self.llm | parser
            llm_result = chain.invoke({"query": user_query, "provinces_list": provinces_str})
            
            target_type = llm_result.get("target_type", "Khu c√¥ng nghi·ªáp")
            filter_type = llm_result.get("filter_type", "specific_zones")
            
            # Logic: M·∫∑c ƒë·ªãnh l√† 'dual' n·∫øu chung chung
            visualization_metric = llm_result.get("visualization_metric", "dual")
            
            # Logic: M·∫∑c ƒë·ªãnh l√† 'bar' n·∫øu kh√¥ng n√≥i r√µ d·∫°ng bi·ªÉu ƒë·ªì
            chart_type = llm_result.get("chart_type", "bar")
            
            keywords = llm_result.get("search_keywords", [])
            numeric_filters = llm_result.get("numeric_filters", [])
            
            # --- LOGIC L·ªåC PYTHON ---
            
            # 1. L·ªçc Lo·∫°i
            if target_type == "C·∫£ hai":
                # L·∫•y c·∫£ KCN v√† CCN
                type_mask = (
                    self.df["Lo·∫°i_norm"].str.contains("khu|kcn", na=False) |
                    self.df["Lo·∫°i_norm"].str.contains("c·ª•m|ccn", na=False)
                )
            elif "c·ª•m" in target_type.lower():
                type_mask = self.df["Lo·∫°i_norm"].str.contains("c·ª•m|ccn", na=False)
            else:
                type_mask = self.df["Lo·∫°i_norm"].str.contains("khu|kcn", na=False)
            df_filtered = self.df[type_mask].copy()

            # 2. L·ªçc T√™n/T·ªânh
            if keywords:
                if filter_type == "province":
                    mask = df_filtered["T·ªânh/Th√†nh ph·ªë"].astype(str).isin(keywords)
                    df_filtered = df_filtered[mask]
                
                elif filter_type == "specific_zones":
                    masks = []
                    for kw in keywords:
                        try:
                            if len(kw) >= 3: 
                                pattern = r"\b" + re.escape(kw.lower())
                                m = df_filtered["T√™n_norm"].str.contains(kw.lower(), regex=False, na=False)
                            else:
                                m = df_filtered["T√™n_norm"].str.contains(kw.lower(), regex=False, na=False)
                        except:
                            m = df_filtered["T√™n_norm"].str.contains(kw.lower(), regex=False, na=False)
                        masks.append(m)
                    
                    if masks:
                        final_mask = pd.concat(masks, axis=1).any(axis=1)
                        df_filtered = df_filtered[final_mask]

            # 3. L·ªçc S·ªë
            for f in numeric_filters:
                metric = f.get("metric")
                op = f.get("operator")
                val = f.get("value")
                
                col = None
                if metric == "price" and "Price_num" in df_filtered.columns:
                    col = "Price_num"
                elif metric == "area" and "Area_num" in df_filtered.columns:
                    col = "Area_num"
                
                if col:
                    if op == ">": df_filtered = df_filtered[df_filtered[col] > val]
                    elif op == "<": df_filtered = df_filtered[df_filtered[col] < val]
                    elif op == ">=": df_filtered = df_filtered[df_filtered[col] >= val]
                    elif op == "<=": df_filtered = df_filtered[df_filtered[col] <= val]
                    elif op == "=": df_filtered = df_filtered[df_filtered[col] == val]

            final_result = {
                "industrial_type": target_type,
                "filter_type": filter_type,
                "visualization_metric": visualization_metric, # Gi√°/Di·ªán t√≠ch/Dual
                "chart_type": chart_type,                     # Bar/Line/Pie/Barh
                "data": df_filtered
            }
            return final_result

        except Exception as e:
            print(f"‚ùå Query Error: {e}")
            return {"filter_type": "error", "message": str(e)}

    def _retrieve_filters_fallback(self, user_query: str) -> Dict[str, Any]:
        """
        Fallback method khi kh√¥ng c√≥ LLM - s·ª≠ d·ª•ng keyword matching
        """
        query_lower = user_query.lower()
        
        # 1. X√°c ƒë·ªãnh target_type
        if any(word in query_lower for word in ["khu v√† c·ª•m", "kcn v√† ccn", "khu c√¥ng nghi·ªáp v√† c·ª•m c√¥ng nghi·ªáp"]):
            target_type = "C·∫£ hai"
            type_mask = (
                self.df["Lo·∫°i_norm"].str.contains("khu|kcn", na=False) |
                self.df["Lo·∫°i_norm"].str.contains("c·ª•m|ccn", na=False)
            )
        elif any(word in query_lower for word in ["c·ª•m", "ccn"]):
            target_type = "C·ª•m c√¥ng nghi·ªáp"
            type_mask = self.df["Lo·∫°i_norm"].str.contains("c·ª•m|ccn", na=False)
        else:
            target_type = "Khu c√¥ng nghi·ªáp"
            type_mask = self.df["Lo·∫°i_norm"].str.contains("khu|kcn", na=False)
        
        df_filtered = self.df[type_mask].copy()
        
        # 2. X√°c ƒë·ªãnh visualization_metric
        if any(word in query_lower for word in ["gi√°", "ti·ªÅn", "usd", "thu√™"]):
            visualization_metric = "price"
        elif any(word in query_lower for word in ["di·ªán t√≠ch", "r·ªông", "quy m√¥", "ha"]):
            visualization_metric = "area"
        else:
            visualization_metric = "dual"
        
        # 3. X√°c ƒë·ªãnh chart_type
        if any(word in query_lower for word in ["tr√≤n", "c∆° c·∫•u", "t·ª∑ l·ªá", "b√°nh"]):
            chart_type = "pie"
        elif any(word in query_lower for word in ["ƒë∆∞·ªùng", "xu h∆∞·ªõng", "bi·∫øn thi√™n"]):
            chart_type = "line"
        elif any(word in query_lower for word in ["ngang", "thanh ngang"]):
            chart_type = "barh"
        else:
            chart_type = "bar"
        
        # 4. T√¨m t·ªânh trong query
        found_province = None
        for province in self.provinces_list:
            if province.lower() in query_lower:
                found_province = province
                break
        
        # 5. L·ªçc theo t·ªânh n·∫øu t√¨m th·∫•y
        if found_province:
            mask = df_filtered["T·ªânh/Th√†nh ph·ªë"].astype(str) == found_province
            df_filtered = df_filtered[mask]
            filter_type = "province"
            search_keywords = [found_province]
        else:
            # Kh√¥ng t√¨m th·∫•y t·ªânh c·ª• th·ªÉ, l·∫•y t·∫•t c·∫£
            filter_type = "specific_zones"
            search_keywords = []
        
        return {
            "industrial_type": target_type,
            "filter_type": filter_type,
            "visualization_metric": visualization_metric,
            "chart_type": chart_type,
            "data": df_filtered
        }

# Export
rag_agent = ExcelQueryAgent()