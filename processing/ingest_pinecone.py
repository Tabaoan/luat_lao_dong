# ===================== IMPORTS =====================
import os
import time
from typing import List, Dict, Any
from pathlib import Path

from dotenv import load_dotenv
load_dotenv(override=True)

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import Pinecone 
from pinecone import Pinecone as PineconeClient, PodSpec
from langchain_community.document_loaders import PyMuPDFLoader

# ===================== Cáº¤U HÃŒNH =====================
OPENAI_API_KEY = os.getenv("OPENAI__API_KEY")
OPENAI_EMBEDDING_MODEL = os.getenv("OPENAI__EMBEDDING_MODEL")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")

EMBEDDING_DIM = 3072  
PDF_FOLDER = r"C:\Users\tabao\Downloads\qd36" 
BATCH_SIZE = 30  

# ===================== KHá»I Táº O =====================
print("ğŸ”§ Äang khá»Ÿi táº¡o Pinecone Client vÃ  Embedding...")

if not all([OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENVIRONMENT, PINECONE_INDEX_NAME]):
    print("âŒ Lá»–I: Thiáº¿u biáº¿n mÃ´i trÆ°á»ng báº¯t buá»™c!")
    print(f"   OPENAI_API_KEY: {'âœ…' if OPENAI_API_KEY else 'âŒ'}")
    print(f"   PINECONE_API_KEY: {'âœ…' if PINECONE_API_KEY else 'âŒ'}")
    print(f"   PINECONE_ENVIRONMENT: {'âœ…' if PINECONE_ENVIRONMENT else 'âŒ'}")
    print(f"   PINECONE_INDEX_NAME: {'âœ…' if PINECONE_INDEX_NAME else 'âŒ'}")
    exit(1)

# Khá»Ÿi táº¡o clients
pc = PineconeClient(api_key=PINECONE_API_KEY)
emb = OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=OPENAI_EMBEDDING_MODEL)

print("âœ… ÄÃ£ khá»Ÿi táº¡o thÃ nh cÃ´ng!\n")

# ===================== HÃ€M Há»– TRá»¢ =====================

def get_pdf_files_from_folder(folder_path: str) -> List[str]:
    """Láº¥y táº¥t cáº£ file PDF trong folder"""
    if not os.path.exists(folder_path):
        print(f"âš ï¸ Folder khÃ´ng tá»“n táº¡i: {folder_path}")
        return []
    
    pdf_files = []
    for file in os.listdir(folder_path):
        if file.lower().endswith('.pdf'):
            full_path = os.path.join(folder_path, file)
            pdf_files.append(full_path)
    
    return sorted(pdf_files)


def get_existing_sources_from_index(index_name: str) -> set:
    """Láº¥y danh sÃ¡ch file Ä‘Ã£ cÃ³ trong Pinecone Index"""
    try:
        if index_name not in pc.list_indexes().names():
            return set()
        
        index = pc.Index(index_name)
        stats = index.describe_index_stats()
        
        if stats['total_vector_count'] == 0:
            return set()
        
        # Query Ä‘á»ƒ láº¥y metadata
        # Táº¡o vector zero Ä‘á»ƒ query
        dummy_query = [0.0] * EMBEDDING_DIM
        results = index.query(
            vector=dummy_query, 
            top_k=10,  # Láº¥y nhiá»u Ä‘á»ƒ Ä‘áº£m báº£o cÃ³ táº¥t cáº£ sources
            include_metadata=True
        )
        
        sources = set()
        for match in results.get('matches', []):
            if 'metadata' in match and 'source' in match['metadata']:
                sources.add(match['metadata']['source'])
        
        return sources
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi láº¥y danh sÃ¡ch file tá»« Index: {e}")
        return set()


def create_or_get_index(index_name: str, force_recreate: bool = False) -> Any:
    """Táº¡o hoáº·c láº¥y Pinecone Index"""
    
    # XÃ³a index náº¿u force_recreate = True
    if force_recreate:
        print(f"ğŸ—‘ï¸ Äang xÃ³a Index '{index_name}' (náº¿u tá»“n táº¡i)...")
        if index_name in pc.list_indexes().names():
            pc.delete_index(index_name)
            print(f"âœ… ÄÃ£ xÃ³a Index '{index_name}'")
            time.sleep(2)  # Äá»£i Pinecone xá»­ lÃ½
    
    # Táº¡o index náº¿u chÆ°a tá»“n táº¡i
    if index_name not in pc.list_indexes().names():
        print(f"ğŸ› ï¸ Äang táº¡o Index '{index_name}'...")
        pc.create_index(
            name=index_name,
            dimension=EMBEDDING_DIM,
            metric='cosine',
            spec=PodSpec(environment=PINECONE_ENVIRONMENT)
        )
        print(f"âœ… ÄÃ£ táº¡o Index '{index_name}'")
        time.sleep(5)  # Äá»£i index sáºµn sÃ ng
    
    return pc.Index(index_name)


def load_and_chunk_pdf(file_path: str) -> List:
    """Äá»c vÃ  chunk má»™t file PDF"""
    filename = os.path.basename(file_path)
    
    try:
        # Load PDF
        loader = PyMuPDFLoader(file_path)
        docs = loader.load()
        
        # Gáº¯n metadata
        for i, doc in enumerate(docs):
            if doc.metadata is None:
                doc.metadata = {}
            doc.metadata["source"] = filename
            doc.metadata["page"] = i + 1
        
        # Chunk documents
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=4000,  
            chunk_overlap=300,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        split_docs = splitter.split_documents(docs)
        
        # Gáº¯n chunk index
        for i, doc in enumerate(split_docs):
            doc.metadata["chunk_id"] = i
        
        return split_docs
        
    except Exception as e:
        print(f"âŒ Lá»—i khi load file {filename}: {e}")
        return []


def ingest_documents_to_pinecone(
    pdf_paths: List[str],
    index_name: str,
    force_reload: bool = False
) -> Dict[str, Any]:
    """
    Náº¡p documents vÃ o Pinecone Index
    
    Args:
        pdf_paths: Danh sÃ¡ch Ä‘Æ°á»ng dáº«n file PDF
        index_name: TÃªn Pinecone Index
        force_reload: Náº¿u True, xÃ³a vÃ  náº¡p láº¡i toÃ n bá»™
    
    Returns:
        Dictionary chá»©a thÃ´ng tin káº¿t quáº£
    """
    
    print("=" * 70)
    print("ğŸš€ Báº®T Äáº¦U QUÃ TRÃŒNH Náº P TÃ€I LIá»†U VÃ€O PINECONE")
    print("=" * 70)
    print(f"ğŸ“ Folder: {PDF_FOLDER}")
    print(f"ğŸ“š Tá»•ng sá»‘ file PDF: {len(pdf_paths)}")
    print(f"â˜ï¸  Index Name: {index_name}")
    print(f"ğŸ”„ Force Reload: {force_reload}\n")
    
    # 1. Táº¡o hoáº·c láº¥y Index
    index = create_or_get_index(index_name, force_recreate=force_reload)
    
    # 2. Láº¥y danh sÃ¡ch file Ä‘Ã£ cÃ³
    if not force_reload:
        print("ğŸ“Š Äang kiá»ƒm tra file Ä‘Ã£ cÃ³ trong Index...")
        existing_sources = get_existing_sources_from_index(index_name)
        print(f"   âœ“ TÃ¬m tháº¥y {len(existing_sources)} file Ä‘Ã£ cÃ³")
        if existing_sources:
            print(f"   â””â”€ {', '.join(sorted(existing_sources))}\n")
    else:
        existing_sources = set()
        print("ğŸ“Š Cháº¿ Ä‘á»™ force reload - Sáº½ náº¡p toÃ n bá»™ file\n")
    
    # 3. XÃ¡c Ä‘á»‹nh file cáº§n náº¡p
    target_files = {os.path.basename(p): p for p in pdf_paths}
    
    if force_reload:
        files_to_load = target_files
        print(f"ğŸ“¥ Sáº½ náº¡p {len(files_to_load)} file\n")
    else:
        new_files = {name: path for name, path in target_files.items() 
                    if name not in existing_sources}
        
        if not new_files:
            print(f"âœ… Táº¥t cáº£ {len(target_files)} file Ä‘Ã£ cÃ³ trong Index!")
            stats = index.describe_index_stats()
            return {
                "success": True,
                "message": "KhÃ´ng cÃ³ file má»›i cáº§n náº¡p",
                "total_vectors": stats['total_vector_count'],
                "files_processed": 0
            }
        
        files_to_load = new_files
        print(f"ğŸ“¥ PhÃ¡t hiá»‡n {len(new_files)} file má»›i cáº§n náº¡p:")
        for name in sorted(new_files.keys()):
            print(f"   + {name}")
        print()
    
    # 4. Load vÃ  chunk táº¥t cáº£ file
    print("ğŸ“– Äang Ä‘á»c vÃ  chunk documents...")
    all_docs = []
    file_stats = {}
    
    for filename, path in files_to_load.items():
        if not os.path.exists(path):
            print(f"   âš ï¸ KhÃ´ng tÃ¬m tháº¥y: {path}")
            continue
        
        print(f"   ğŸ“„ {filename}...", end=" ")
        chunks = load_and_chunk_pdf(path)
        
        if chunks:
            all_docs.extend(chunks)
            file_stats[filename] = len(chunks)
            print(f"âœ“ {len(chunks)} chunks")
        else:
            print(f"âœ— Lá»—i")
    
    if not all_docs:
        print("\nâš ï¸ KhÃ´ng cÃ³ document nÃ o Ä‘á»ƒ náº¡p!")
        return {
            "success": False,
            "message": "KhÃ´ng cÃ³ document nÃ o Ä‘Æ°á»£c load thÃ nh cÃ´ng",
            "files_processed": 0
        }
    
    print(f"\nğŸ“š Tá»•ng cá»™ng: {len(all_docs)} chunks tá»« {len(file_stats)} file\n")
    
    # 5. Náº¡p vÃ o Pinecone theo batch
    print("ğŸ’¾ Äang náº¡p vÃ o Pinecone Index...")
    print(f"ğŸ“¦ Batch size: {BATCH_SIZE} documents/batch\n")
    
    total_batches = (len(all_docs) + BATCH_SIZE - 1) // BATCH_SIZE
    vectordb = None
    
    try:
        for i in range(0, len(all_docs), BATCH_SIZE):
            batch_num = (i // BATCH_SIZE) + 1
            batch = all_docs[i:i + BATCH_SIZE]
            
            print(f"   ğŸ“¦ Batch {batch_num}/{total_batches} ({len(batch)} docs)...", end=" ")
            
            if i == 0:
                # Batch Ä‘áº§u tiÃªn: Táº¡o vectordb
                vectordb = Pinecone.from_documents(
                    batch,
                    index_name=index_name,
                    embedding=emb,
                    text_key="text"
                )
            else:
                # CÃ¡c batch tiáº¿p theo: ThÃªm vÃ o vectordb
                vectordb.add_documents(batch)
            
            print("âœ“")
            time.sleep(1)  # TrÃ¡nh rate limit
        
        print("\nâœ… ÄÃ£ náº¡p toÃ n bá»™ documents thÃ nh cÃ´ng!")
        
    except Exception as e:
        print(f"\nâŒ Lá»—i khi náº¡p vÃ o Pinecone: {e}")
        return {
            "success": False,
            "message": str(e),
            "files_processed": len(file_stats)
        }
    
    # 6. Thá»‘ng kÃª cuá»‘i cÃ¹ng
    stats = index.describe_index_stats()
    
    print("\n" + "=" * 70)
    print("ğŸ“Š THá»NG KÃŠ Káº¾T QUáº¢")
    print("=" * 70)
    print(f"âœ… Tá»•ng vectors trong Index: {stats['total_vector_count']}")
    print(f"ğŸ“ Sá»‘ file Ä‘Ã£ xá»­ lÃ½: {len(file_stats)}")
    print(f"ğŸ“„ Chi tiáº¿t:")
    for filename, chunks in sorted(file_stats.items()):
        print(f"   â€¢ {filename}: {chunks} chunks")
    print("=" * 70 + "\n")
    
    return {
        "success": True,
        "message": "Náº¡p tÃ i liá»‡u thÃ nh cÃ´ng",
        "total_vectors": stats['total_vector_count'],
        "files_processed": len(file_stats),
        "file_stats": file_stats
    }


# ===================== MAIN =====================
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Tá»± Ä‘á»™ng náº¡p tÃ i liá»‡u PDF vÃ o Pinecone Index"
    )
    parser.add_argument(
        "--force-reload",
        action="store_true",
        help="XÃ³a vÃ  náº¡p láº¡i toÃ n bá»™ (máº·c Ä‘á»‹nh: chá»‰ náº¡p file má»›i)"
    )
    parser.add_argument(
        "--folder",
        type=str,
        default=PDF_FOLDER,
        help=f"ÄÆ°á»ng dáº«n folder chá»©a PDF (máº·c Ä‘á»‹nh: {PDF_FOLDER})"
    )
    
    args = parser.parse_args()
    
    # Láº¥y danh sÃ¡ch file PDF
    pdf_files = get_pdf_files_from_folder(args.folder)
    
    if not pdf_files:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file PDF nÃ o trong folder: {args.folder}")
        exit(1)
    
    print(f"ğŸ“š TÃ¬m tháº¥y {len(pdf_files)} file PDF:")
    for idx, path in enumerate(pdf_files, 1):
        status = "âœ…" if os.path.exists(path) else "âŒ"
        print(f"   {idx}. {status} {os.path.basename(path)}")
    print()
    
    # XÃ¡c nháº­n trÆ°á»›c khi thá»±c hiá»‡n
    if args.force_reload:
        confirm = input("âš ï¸  Báº¡n sáº¯p XÃ“A vÃ  Náº P Láº I toÃ n bá»™ Index. Tiáº¿p tá»¥c? (yes/no): ")
        if confirm.lower() != "yes":
            print("âŒ ÄÃ£ há»§y")
            exit(0)
    
    # Thá»±c hiá»‡n náº¡p tÃ i liá»‡u
    result = ingest_documents_to_pinecone(
        pdf_paths=pdf_files,
        index_name=PINECONE_INDEX_NAME,
        force_reload=args.force_reload
    )
    
    # Hiá»ƒn thá»‹ káº¿t quáº£
    if result["success"]:
        print("ğŸ‰ HOÃ€N THÃ€NH!")
    else:
        print("âŒ CÃ“ Lá»–I Xáº¢Y RA!")
        print(f"   LÃ½ do: {result['message']}")
        exit(1)