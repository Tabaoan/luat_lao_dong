"""
Module x·ª≠ l√Ω truy v·∫•n tr·ª±c ti·∫øp file Excel v·ªÅ KCN/CCN
T√≠ch h·ª£p v√†o chatbot ƒë·ªÉ tr·∫£ v·ªÅ d·ªØ li·ªáu d·∫°ng JSON khi ng∆∞·ªùi d√πng h·ªèi
v·ªÅ s·ªë l∆∞·ª£ng ho·∫∑c danh s√°ch khu/c·ª•m c√¥ng nghi·ªáp.
"""

import pandas as pd
import re
import json
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path


class ExcelQueryHandler:
    def __init__(self, excel_path: str):
        """
        Kh·ªüi t·∫°o handler v·ªõi ƒë∆∞·ªùng d·∫´n file Excel

        Args:
            excel_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel ch·ª©a th√¥ng tin KCN/CCN
        """
        self.excel_path = excel_path
        self.df = None

        # Khai b√°o c√°c c·ªôt c·∫ßn thi·∫øt
        self.columns_map = {
            "province": None,
            "type": None,  # C·ªôt Lo·∫°i (KCN/CCN)
            "name": None,
            "address": None,
            "operation_time": None,
            "area": None,
            "rental_price": None,
            "industry": None
        }

        self._load_excel()

    # ==========================================================
    # üß© LOAD FILE EXCEL & NH·∫¨N DI·ªÜN C·ªòT
    # ==========================================================
    def _load_excel(self):
        """Load file Excel v√† t·ª± ƒë·ªông ph√°t hi·ªán c√°c c·ªôt quan tr·ªçng"""
        try:
            self.df = pd.read_excel(self.excel_path)
            self.df.columns = self.df.columns.str.strip()

            for col in self.df.columns:
                col_lower = col.lower()
                if any(k in col_lower for k in ["t·ªânh", "th√†nh ph·ªë", "province"]):
                    self.columns_map["province"] = col
                elif any(k in col_lower for k in ["lo·∫°i", "loai", "type"]):
                    self.columns_map["type"] = col
                elif any(k in col_lower for k in ["t√™n", "ten", "kcn", "ccn"]) and "lo·∫°i" not in col_lower:
                    self.columns_map["name"] = col
                elif any(k in col_lower for k in ["ƒë·ªãa ch·ªâ", "dia chi", "address"]):
                    self.columns_map["address"] = col
                elif any(k in col_lower for k in ["th·ªùi gian", "v·∫≠n h√†nh", "operation"]):
                    self.columns_map["operation_time"] = col
                elif any(k in col_lower for k in ["di·ªán t√≠ch", "dien tich", "area"]):
                    self.columns_map["area"] = col
                elif any(k in col_lower for k in ["gi√° thu√™", "gia thue", "rent", "rental"]):
                    self.columns_map["rental_price"] = col
                elif any(k in col_lower for k in ["ng√†nh ngh·ªÅ", "nganh nghe", "industry"]):
                    self.columns_map["industry"] = col

            print(f"‚úÖ ƒê√£ load Excel: {len(self.df)} b·∫£n ghi")
            print("üß≠ C·∫•u tr√∫c c·ªôt nh·∫≠n di·ªán ƒë∆∞·ª£c:")
            for key, val in self.columns_map.items():
                print(f"   - {key}: {val}")

        except Exception as e:
            print(f"‚ùå L·ªói khi load Excel: {e}")
            self.df = None

    # ==========================================================
    # üß† NH·∫¨N DI·ªÜN C√ÇU H·ªéI NG∆Ø·ªúI D√ôNG
    # ==========================================================
    def is_count_query(self, question: str) -> bool:
        """
        Nh·∫≠n di·ªán c√¢u h·ªèi v·ªÅ ƒë·∫øm ho·∫∑c li·ªát k√™ KCN/CCN.
        """
        question_norm = self._normalize_text(question.lower())

        # C√°c nh√≥m t·ª´ kh√≥a
        count_keywords = [
            "bao nhieu", "so luong", "tong so", "dem", "ke ten",
            "liet ke", "cho biet", "bao gom", "ke ra",
            "danh sach", "toan bo", "danh muc", "cac", "nhung", "o", "tai"
        ]

        industrial_keywords = [
            "kcn", "ccn", "khu cong nghiep", "cum cong nghiep",
            "khu cn", "cum cn", "khu nghiep", "cum nghiep", "cong nghiep"
        ]

        # N·∫øu c√≥ c·ª•m c√¥ng nghi·ªáp ho·∫∑c khu c√¥ng nghi·ªáp trong c√¢u
        has_industrial = any(k in question_norm for k in industrial_keywords)

        # N·∫øu c√≥ t·ª´ kh√≥a li·ªát k√™
        has_count = any(k in question_norm for k in count_keywords)

        # Ch·∫•p nh·∫≠n n·∫øu c√≥ industrial keywords (v√¨ th∆∞·ªùng khi h·ªèi v·ªÅ KCN/CCN l√† mu·ªën tra c·ª©u)
        return has_industrial

    # ==========================================================
    # üß≠ X√ÅC ƒê·ªäNH LO·∫†I TRUY V·∫§N (KHU / C·ª§M)
    # ==========================================================
    def detect_type(self, question: str) -> Optional[str]:
        """
        X√°c ƒë·ªãnh ng∆∞·ªùi d√πng h·ªèi khu hay c·ª•m c√¥ng nghi·ªáp.
        ∆Øu ti√™n t·ª´ kh√≥a c·ª• th·ªÉ tr∆∞·ªõc.
        """
        q = self._normalize_text(question)
        
        # Ki·ªÉm tra C·ª§M tr∆∞·ªõc (v√¨ "c·ª•m" c·ª• th·ªÉ h∆°n)
        if any(k in q for k in ["cum cong nghiep", "ccn", "cum cn", "cum nghiep"]):
            return "CCN"
        
        # Ki·ªÉm tra KHU sau
        if any(k in q for k in ["khu cong nghiep", "kcn", "khu cn", "khu nghiep"]):
            return "KCN"
        
        # N·∫øu ch·ªâ c√≥ "c√¥ng nghi·ªáp" chung chung th√¨ tr·∫£ v·ªÅ None
        if "cong nghiep" in q:
            return None
            
        return None

    # ==========================================================
    # üß© TR√çCH XU·∫§T T·ªàNH/TH√ÄNH PH·ªê
    # ==========================================================
    def extract_province(self, question: str) -> Optional[str]:
        """Tr√≠ch xu·∫•t t√™n t·ªânh/th√†nh ph·ªë t·ª´ c√¢u h·ªèi"""
        if self.df is None or self.columns_map["province"] is None:
            return None

        question_norm = self._normalize_text(question.lower())
        unique_provinces = self.df[self.columns_map["province"]].dropna().unique()

        for prov in unique_provinces:
            prov_norm = self._normalize_text(str(prov))
            if prov_norm in question_norm:
                return prov

        if any(k in question_norm for k in ["toan quoc", "ca nuoc", "viet nam", "vn"]):
            return "TO√ÄN QU·ªêC"

        return None

    # ==========================================================
    # üî° CHU·∫®N H√ìA TEXT (B·ªé D·∫§U)
    # ==========================================================
    def _normalize_text(self, text: str) -> str:
        intab = "√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë"
        outtab = "aaaaaaaaaaaaaaaaaeeeeeeeeeeeiiiiiooooooooooooooooouuuuuuuuuuuyyyyyd"
        intab_upper = "√Ä√Å·∫¢√É·∫†ƒÇ·∫Æ·∫∞·∫≤·∫¥·∫∂√Ç·∫§·∫¶·∫®·∫™·∫¨√à√â·∫∫·∫º·∫∏√ä·∫æ·ªÄ·ªÇ·ªÑ·ªÜ√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªê·ªí·ªî·ªñ·ªò∆†·ªö·ªú·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª®·ª™·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥ƒê"
        outtab_upper = "AAAAAAAAAAAAAAAAAEEEEEEEEEEEIIIIIOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYD"
        transtab = str.maketrans(intab + intab_upper, outtab + outtab_upper)
        return text.translate(transtab).lower()

    # ==========================================================
    # üîç TRUY V·∫§N D·ªÆ LI·ªÜU
    # ==========================================================
    def query_by_province(self, province_name: str, query_type: Optional[str]) -> Optional[pd.DataFrame]:
        """
        L·ªçc d·ªØ li·ªáu theo t·ªânh/th√†nh ph·ªë v√† lo·∫°i (KCN/CCN).
        S·ª≠ d·ª•ng c·ªôt "Lo·∫°i" c√≥ s·∫µn trong Excel ƒë·ªÉ l·ªçc ch√≠nh x√°c.
        """
        if self.df is None or self.columns_map["province"] is None:
            return None

        # L·ªçc theo t·ªânh/th√†nh ph·ªë
        if province_name == "TO√ÄN QU·ªêC":
            df_filtered = self.df.copy()
        else:
            df_filtered = self.df[
                self.df[self.columns_map["province"]].astype(str).str.lower().str.contains(
                    province_name.lower(), na=False
                )
            ].copy()

        # L·ªçc theo lo·∫°i KCN/CCN d·ª±a v√†o c·ªôt "Lo·∫°i"
        if query_type and self.columns_map["type"] is not None:
            df_filtered = df_filtered[
                df_filtered[self.columns_map["type"]].astype(str).str.strip().str.upper() == query_type
            ]

        return df_filtered

    # ==========================================================
    # üßæ TR·∫¢ K·∫æT QU·∫¢ D·∫†NG JSON
    # ==========================================================
    def format_json_response(self, df: pd.DataFrame, province_name: str, query_type: Optional[str]) -> str:
        """Tr·∫£ k·∫øt qu·∫£ truy v·∫•n d·∫°ng JSON"""
        if df is None or df.empty:
            label = "khu" if query_type == "KCN" else "c·ª•m" if query_type == "CCN" else "khu/c·ª•m"
            return json.dumps({
                "province": province_name,
                "type": query_type,
                "count": 0,
                "message": f"Kh√¥ng t√¨m th·∫•y {label} c√¥ng nghi·ªáp t·∫°i {province_name}.",
                "data": []
            }, ensure_ascii=False, indent=2)

        cols = self.columns_map
        records = []

        for _, row in df.iterrows():
            item = {
                "T·ªânh/Th√†nh ph·ªë": str(row.get(cols["province"], "")),
                "Lo·∫°i": str(row.get(cols["type"], "")),
                "T√™n": str(row.get(cols["name"], "")),
                "ƒê·ªãa ch·ªâ": str(row.get(cols["address"], "")),
                "Th·ªùi gian v·∫≠n h√†nh": str(row.get(cols["operation_time"], "")),
                "T·ªïng di·ªán t√≠ch": str(row.get(cols["area"], "")),
                "Gi√° thu√™ ƒë·∫•t": str(row.get(cols["rental_price"], "")),
                "Ng√†nh ngh·ªÅ": str(row.get(cols["industry"], "")),
            }
            records.append(item)

        label = "khu" if query_type == "KCN" else "c·ª•m" if query_type == "CCN" else "khu/c·ª•m"
        response = {
            "province": province_name,
            "type": query_type,
            "count": len(df),
            "message": f"{province_name} c√≥ {len(df)} {label} c√¥ng nghi·ªáp.",
            "data": records
        }

        return json.dumps(response, ensure_ascii=False, indent=2)

    # ==========================================================
    # ‚öôÔ∏è X·ª¨ L√ù TRUY V·∫§N NG∆Ø·ªúI D√ôNG
    # ==========================================================
    def process_query(self, question: str, return_json: bool = True) -> Tuple[bool, Optional[str]]:
        """X·ª≠ l√Ω truy v·∫•n v√† tr·∫£ k·∫øt qu·∫£ (JSON m·∫∑c ƒë·ªãnh)"""
        if not self.is_count_query(question):
            return False, None

        province = self.extract_province(question)
        if province is None:
            return False, json.dumps({"error": "‚ùì B·∫°n vui l√≤ng n√™u r√µ t·ªânh/th√†nh ph·ªë c·∫ßn tra c·ª©u."}, ensure_ascii=False)

        query_type = self.detect_type(question)
        
        # N·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c lo·∫°i, y√™u c·∫ßu l√†m r√µ
        if query_type is None:
            return False, json.dumps({
                "error": "‚ùì B·∫°n mu·ªën tra c·ª©u KHU c√¥ng nghi·ªáp hay C·ª§M c√¥ng nghi·ªáp? Vui l√≤ng n√™u r√µ."
            }, ensure_ascii=False)

        df_result = self.query_by_province(province, query_type)

        if return_json:
            return True, self.format_json_response(df_result, province, query_type)
        else:
            return True, self.format_table_response(df_result, province, query_type)

    # ==========================================================
    # üß© GI·ªÆ L·∫†I H√ÄM C≈® (B·∫¢NG TEXT)
    # ==========================================================
    def format_table_response(self, df: pd.DataFrame, province_name: str, query_type: Optional[str]) -> str:
        """(Tu·ª≥ ch·ªçn) Hi·ªÉn th·ªã k·∫øt qu·∫£ d·∫°ng b·∫£ng text"""
        if df is None or df.empty:
            label = "khu" if query_type == "KCN" else "c·ª•m" if query_type == "CCN" else "khu/c·ª•m"
            return f"Kh√¥ng t√¨m th·∫•y {label} c√¥ng nghi·ªáp t·∫°i {province_name}."

        cols = self.columns_map
        label = "khu" if query_type == "KCN" else "c·ª•m" if query_type == "CCN" else "khu/c·ª•m"
        response = f"üìä {province_name} c√≥ {len(df)} {label} c√¥ng nghi·ªáp.\n\n"
        for _, row in df.iterrows():
            response += f"- {row.get(cols['name'], 'Kh√¥ng r√µ')} ({row.get(cols['address'], '')})\n"
        return response


# ==========================================================
# üîå T√çCH H·ª¢P V√ÄO CHATBOT
# ==========================================================
def integrate_excel_to_chatbot(excel_path: str):
    """T√≠ch h·ª£p module Excel v√†o chatbot"""
    if not Path(excel_path).exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file Excel: {excel_path}")
        return None
    handler = ExcelQueryHandler(excel_path)
    print("‚úÖ ƒê√£ t√≠ch h·ª£p module truy v·∫•n Excel.")
    return handler


# ==========================================================
# üß™ TEST MODULE
# ==========================================================
if __name__ == "__main__":
    EXCEL_FILE = r"./data/IIPMap_FULL_63_COMPLETE.xlsx"
    handler = ExcelQueryHandler(EXCEL_FILE)

    test_queries = [
        "Danh s√°ch c·ª•m c√¥ng nghi·ªáp ·ªü B·∫Øc Ninh"
    ]

    print("\n" + "=" * 80)
    print("TEST MODULE TR·∫¢ K·∫æT QU·∫¢ D·∫†NG JSON")
    print("=" * 80)

    for query in test_queries:
        print(f"\n‚ùì {query}")
        handled, response = handler.process_query(query, return_json=True)
        if handled:
            print(response)
        else:
            print("‚è≠Ô∏è B·ªè qua - Kh√¥ng ph·∫£i c√¢u h·ªèi li·ªát k√™ KCN/CCN ho·∫∑c thi·∫øu th√¥ng tin")
        print("-" * 80)